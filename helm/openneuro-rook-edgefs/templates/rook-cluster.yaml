apiVersion: v1
kind: ServiceAccount
metadata:
  name: rook-edgefs-cluster
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: rook-edgefs-cluster
rules:
  - apiGroups: ['']
    resources: ['configmaps', 'endpoints']
    verbs: ['get', 'list', 'watch', 'create', 'update', 'delete']
  - apiGroups: ['edgefs.rook.io']
    resources: ['*']
    verbs: ['*']
  - apiGroups: ['']
    resources: ['pods']
    verbs: ['get', 'list']
  - apiGroups: ['extensions']
    resources: ['deployments/scale']
    verbs: ['get', 'update']
---
# Allow the operator to create resources in this cluster's namespace
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: rook-edgefs-cluster-mgmt
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: rook-edgefs-cluster-mgmt
subjects:
  - kind: ServiceAccount
    name: rook-edgefs-system
    # TODO - Generalize this?
    namespace: rook-edgefs-system
---
# Allow the pods in this namespace to work with configmaps
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: rook-edgefs-cluster
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: rook-edgefs-cluster
subjects:
  - kind: ServiceAccount
    name: rook-edgefs-cluster
    namespace: rook-edgefs
---
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: privileged
  namespace: default
spec:
  fsGroup:
    rule: RunAsAny
  privileged: true
  runAsUser:
    rule: RunAsAny
  seLinux:
    rule: RunAsAny
  supplementalGroups:
    rule: RunAsAny
  volumes:
    - '*'
  allowedCapabilities:
    - '*'
  hostPID: true
  hostIPC: true
  hostNetwork: false
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: privileged-psp-user
rules:
  - apiGroups:
      - apps
    resources:
      - podsecuritypolicies
    resourceNames:
      - privileged
    verbs:
      - use
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: rook-edgefs-system-psp
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: privileged-psp-user
subjects:
  - kind: ServiceAccount
    name: rook-edgefs-system
    namespace: rook-edgefs-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: rook-edgefs-cluster-psp
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: privileged-psp-user
subjects:
  - kind: ServiceAccount
    name: rook-edgefs-cluster
    namespace: rook-edgefs
---
apiVersion: edgefs.rook.io/v1
kind: Cluster
metadata:
  name: rook-edgefs
spec:
  edgefsImageName: edgefs/edgefs:{{ .Values.edgefs.version }}
  serviceAccount: rook-edgefs-cluster
  dataVolumeSize: '{{ .Values.edgefs.dataVolumeSize }}'
  #devicesResurrectMode: "restoreZapWait"
  #dashboard:
  #  localAddr: 10.3.30.75
  storage: # cluster level storage configuration and selection
    useAllDevices: true
    config:
      mdReserved: '30' # allocate only 30% of offloaded SSD/NVMe slice for Metadata, the rest keep for BCache
      hddReadAhead: '2048' # speed up reads of 2MB+ chunks of HDD (offload use case)
      rtVerifyChid: '0' # may improve CPU utilization
      lmdbPageSize: '32768' # larger value can improve stream operations
      lmdbMdPageSize: '4096' # smaller value can improve metadata offload device utilization
      useMetadataOffload: 'true' # enable use of SSD device as metadata offload
      useBCache: 'true' # enable SSD cache device and read-cache
      useBCacheWB: 'true' # enable SSD write-cache
      #    useMetadataMask: "0x7d"     # all metadata on SSD except second level manifests
      #    rtPLevelOverride: "4"       # enable large device partitioning, only needed if automatic not working
      sync: '0' # highest performance, consistent on pod/software failures, not-consistent on power failures
  #    useAllSSD: "true"           # use only SSDs during deployment
  #    zone: "1"                   # defines failure domain's zone number for all edgefs nodes
  resources:
    limits:
      cpu: '2'
      memory: '4096Mi'
    requests:
      cpu: '2'
      memory: '4096Mi'
  placement:
    all:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: alpha.eksctl.io/nodegroup-name
                  operator: In
                  values:
                    - edgefs-target
      tolerations:
        - key: taintKey
          operator: Exists
