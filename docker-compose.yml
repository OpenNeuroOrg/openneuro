# docker compose versions
version: '2.3'

# shared volumes
volumes:
  project:
  yarn_cache:

services:
  # web app bundle build
  app:
    build:
      context: .
      dockerfile: ./packages/openneuro-app/Dockerfile
      target: app
    working_dir: /srv/packages/openneuro-app
    command: sh -c "apk add make gcc g++ python && yarn install && yarn start"
    volumes:
      - .:/srv
      - yarn_cache:/root/.cache
      - project:/srv/packages/openneuro-app/dist
    ports:
      - '8145:8145'
    tmpfs:
      - /srv/node_modules:exec
      - /srv/packages/openneuro-app/node_modules:exec
      - /srv/packages/openneuro-client/node_modules:exec
      - /srv/packages/openneuro-cli/node_modules:exec
      - /srv/packages/openneuro-server/node_modules:exec
      - /srv/packages/openneuro-indexer/node_modules:exec

  content:
    image: ${CONTENT_IMAGE}
    volumes:
      - /content

  # mongodb
  mongo:
    image: mongo:4.0
    volumes:
      - ${PERSISTENT_DIR}/mongo:/data/db

  # Redis
  redis:
    image: redis:alpine
    volumes:
      - ${PERSISTENT_DIR}/redis:/data

  # crn node server
  server:
    build:
      context: ./packages/openneuro-server
    command: sh -c "apk add make gcc g++ python && yarn install && node --trace-warnings /srv/index.js"
    volumes:
      - ./packages/openneuro-server:/srv
      - yarn_cache:/root/.cache
      - ${PERSISTENT_DIR}/bids-core/persistent/data:/srv/bids-core/persistent/data
      - ${PERSISTENT_DIR}/crn-server/persistent:/srv/persistent
    tmpfs:
      - /srv/node_modules:exec
    env_file: ./config.env
    depends_on:
      - redis
      - mongo
      - datalad
      - elasticsearch

  # datalad Python backend
  datalad:
    image: openneuro/datalad-service:${DATALAD_SERVICE_TAG}
    volumes:
      - ${PERSISTENT_DIR}/datalad:/datalad
      - ../datalad-service/datalad_service:/datalad_service
    env_file: ./config.env
    depends_on:
      - celery
    init: true

  # celery Python backend
  celery:
    image: openneuro/datalad-service:${DATALAD_SERVICE_TAG}
    command:
      - /dataset-worker
    scale: 4
    volumes:
      - ${PERSISTENT_DIR}/datalad:/datalad
      - ../datalad-service/datalad_service:/datalad_service
      - ../datalad-service/tests:/tests
    env_file: ./config.env
    init: true

  # publish-only celery worker
  publish:
    image: openneuro/datalad-service:${DATALAD_SERVICE_TAG}
    command:
      - /publish-worker
    volumes:
      - ${PERSISTENT_DIR}/datalad:/datalad
      - ../datalad-service/datalad_service:/datalad_service
      - ./datalad-key:/datalad-key
    env_file: ./config.env
    init: true

  flower:
    image: openneuro/datalad-service:${DATALAD_SERVICE_TAG}
    command:
      - flower
      - -A
      - datalad_service.worker
      - --broker
      - redis://redis
    env_file: ./config.env
    ports:
      - '5555:5555'

  # nginx + app
  web:
    image: openneuro/app:${CRN_APP_TAG}
    volumes:
      - ./nginx/nginx.dev.conf:/etc/nginx/conf.d/default.conf:ro
      - ./nginx/.htpasswd:/etc/nginx/.htpasswd:ro
      - ./acme:/acme
      - ${SSL_DIR}:/etc/nginx/ssl
    volumes_from:
      - content
    ports:
      - '80:80'
      - '8110:8110'
      - '443:443'
      - '9876:80'
    depends_on:
      - server
      - datalad

  elasticsearch:
    image: elasticsearch:7.5.1
    environment:
      discovery.type: single-node
      cluster.routing.allocation.disk.threshold_enabled: 'true'
      cluster.routing.allocation.disk.watermark.flood_stage: 1gb
      cluster.routing.allocation.disk.watermark.low: 10gb
      cluster.routing.allocation.disk.watermark.high: 5gb
    ports:
      - '9200:9200'
      - '9300:9300'

  indexer:
    build:
      context: .
      dockerfile: ./packages/openneuro-indexer/Dockerfile
      target: indexer
    depends_on:
      - server
    env_file: ./config.env
    volumes:
      - ./packages/openneuro-indexer/src:/srv/packages/openneuro-indexer/src
